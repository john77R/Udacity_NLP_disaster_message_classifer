{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\jringros\\AppData\\Loc\n",
      "[nltk_data]     al\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\jringros\\AppData\\L\n",
      "[nltk_data]     ocal\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\jringros\\AppData\n",
      "[nltk_data]     \\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\nltk_da\n",
      "[nltk_data]     ta...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "import sqlite3\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_data():#database_filepath):\n",
    "    \n",
    "    ''' Load a database and provides attribute variable, target variables and headers corresponding to target variables\n",
    "    \n",
    "    INPUT:\n",
    "    database_filepath - path of the .db file (database) created and stored by the process_data.py script\n",
    "   \n",
    "    \n",
    "    OUTPUT:\n",
    "    X - dataframe corresponding to the attribute variable (1 column, that corresponds to the text contained in the disaster_message.csv file which is input of the process_data.py script)\n",
    "    Y - dataframe corresponding to the target variables (36 columns, correspond to each value of the \"categories\" column contained in the categories_message.csv file which is input of the                     process_data.py script) \n",
    "    category_names - headers of the Y dataframe\n",
    "    '''\n",
    "    conn = sqlite3.connect('messages.db')\n",
    "\n",
    "    df=pd.read_sql('SELECT * FROM messages', conn)\n",
    "    \n",
    "    \n",
    "    #engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "   \n",
    "    #df = pd.read_sql_table('DisasterResponseTable', engine) \n",
    "    \n",
    "    df = df.replace(to_replace='None', value=np.nan)\n",
    "    \n",
    "    df=df[df[\"message\"]!='#NAME?']\n",
    "    \n",
    "    #X = df[\"message\"]\n",
    "    X = pd.Series(df['message'])\n",
    "    Y = df.drop(['id','message','original','genre'], axis=1)\n",
    "    \n",
    "    category_names = Y.columns\n",
    "    \n",
    "    return X, Y, category_names\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, category_names =load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4    says: west side of Haiti, rest of the country ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    ''' Tokenizes and normalizes the input text, removes stop words and symbols apart from letters and numbers\n",
    "    \n",
    "    INPUT:\n",
    "    df- a text (string format)\n",
    "      \n",
    "    \n",
    "    OUTPUT:\n",
    "    clear tokens- a list of strings, obtained as a result of the following operations on the input text:\n",
    "            - Everything but letters (uppercase und lowercase) and numbers will be removed\n",
    "            - Text will be divided into separate elements, or \"tokens\"\n",
    "            - Stop words corresponding to the English language will be removed\n",
    "            - Tokens will be lemmatized, i.e. tokens will be converted into \"root words\",\n",
    "                based on WordNetLemmatizer\n",
    "            - Tokens will be lemmatized, i.e. tokens will be converted into \"root words\"\n",
    "            - Tokens will be normalized\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    # normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text)\n",
    "   \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # remove tokens corresponding to stop words\n",
    "    tokens = [word for word in tokens if not word in stopwords.words(\"english\")]\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # iterate through each token\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        \n",
    "        # lemmatize, normalize case, and remove leading/trailing white space\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens \n",
    "    \n",
    "    #pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    '''  Builds a pipeline model\n",
    "    \n",
    "    OUTPUT:\n",
    "    model_pipeline - A pipeline-based model with the following characteristics:\n",
    "            - makes use of \"CountVectorizer\" as vectorizer\n",
    "            - makes use of \"TfidfTransformer\" as transformer\n",
    "            - makes use of \"MultiOutputClassifier\", subtype \"RandomForestClassifier\", as classifier\n",
    "            - makes use of GridSearchCV in order to find the optimal combination of differemt hyperparameters\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(KNeighborsClassifier()))    ])\n",
    "    \n",
    "    parameters = {\n",
    "    \n",
    "       'vect__ngram_range': [(1, 1)],\n",
    "    \n",
    "       'vect__max_df': [0.5],\n",
    "       'vect__max_features': [None],\n",
    "\n",
    "       'clf__estimator__n_neighbors': [2]\n",
    "                } \n",
    "    \n",
    "    \n",
    "    cv = GridSearchCV(pipeline, parameters,verbose=3)\n",
    "    #print(cv)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, model):\n",
    "    \n",
    "    ''' Fits the model with the train components of X and Y\n",
    "    \n",
    "    INPUT:\n",
    "    X_train - train component of the dataframe corresponding to the attribute variable\n",
    "    y_train - train component of the dataframe corresponding to the target variable\n",
    "    model - mathematical model that will be fitted with the train components of attribute variable X and target attribute y\n",
    "   \n",
    "    OUTPUT:\n",
    "    model - mathematical model that was inserted as input of the function, already fitted with X_test and y_test   \n",
    "   \n",
    "    '''\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(cv, X_test, y_test, category_names):    \n",
    "    \n",
    "    ''' Evaluates the model, providing the test_score by using ClassificationReport (useful for multi-target models)\n",
    "    \n",
    "    INPUT:\n",
    "    model - mathematical model that was already fitted with X_test and y_test in the train function \n",
    "    X_test - dataframe that corresponds to the train component of the attribute variable X\n",
    "    y_test - contains the train component of the target variable yy - dataframe corresponding to the target variable; will be divided into train ant test sets\n",
    " \n",
    "   \n",
    "    '''    \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # y_test_pred and y_train_pred are obtaines as numpy arrays\n",
    "    # for further operations, we need to convert them into dataframe\n",
    "    # therefore, y_test_pred_df and y_train_pred_df are introduced:\n",
    "\n",
    "    y_headers = y_test.columns\n",
    "\n",
    "    y_test_pred_df = pd.DataFrame(y_test_pred, columns = y_headers)\n",
    "\n",
    "    \n",
    "    for col in y_test:\n",
    "        test_score = classification_report(y_test[col],y_test_pred_df[col],)\n",
    "        #print(\"\\nBest Parameters:\", cv.best_params_)\n",
    "        print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    \n",
    "    ''' Saves the model as a pickle file\n",
    "    \n",
    "    INPUT:\n",
    "    model - mathematical model that was already fitted with X_test and y_test in the train function \n",
    "    model_filepath - path where model will be saved\n",
    "   \n",
    "    '''       \n",
    "    \n",
    "    #pkl_filename = '{}'.format(model_filepath)\n",
    "    #with open(pkl_model, 'wb') as file:\n",
    "        #pickle.dump(model, file)\n",
    "    filename = 'classifier.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Training model...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1);, score=0.231 total time= 9.3min\n",
      "[CV 2/5] END clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1);, score=0.086 total time= 9.3min\n",
      "[CV 3/5] END clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1);, score=0.265 total time= 9.1min\n",
      "[CV 4/5] END clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1);, score=0.236 total time= 9.3min\n",
      "[CV 5/5] END clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1);, score=0.240 total time= 9.2min\n",
      "Evaluating model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.25      0.35      1266\n",
      "           1       0.79      0.95      0.86      3941\n",
      "           2       1.00      0.03      0.07        29\n",
      "\n",
      "    accuracy                           0.78      5236\n",
      "   macro avg       0.80      0.41      0.43      5236\n",
      "weighted avg       0.75      0.78      0.74      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91      4355\n",
      "           1       0.78      0.10      0.18       881\n",
      "\n",
      "    accuracy                           0.84      5236\n",
      "   macro avg       0.81      0.55      0.55      5236\n",
      "weighted avg       0.83      0.84      0.79      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5206\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.99      0.99      0.99      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74      3054\n",
      "           1       0.78      0.05      0.09      2182\n",
      "\n",
      "    accuracy                           0.60      5236\n",
      "   macro avg       0.69      0.52      0.42      5236\n",
      "weighted avg       0.67      0.60      0.47      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4819\n",
      "           1       0.50      0.00      0.00       417\n",
      "\n",
      "    accuracy                           0.92      5236\n",
      "   macro avg       0.71      0.50      0.48      5236\n",
      "weighted avg       0.89      0.92      0.88      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4969\n",
      "           1       0.50      0.01      0.01       267\n",
      "\n",
      "    accuracy                           0.95      5236\n",
      "   macro avg       0.72      0.50      0.49      5236\n",
      "weighted avg       0.93      0.95      0.92      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5068\n",
      "           1       1.00      0.01      0.01       168\n",
      "\n",
      "    accuracy                           0.97      5236\n",
      "   macro avg       0.98      0.50      0.50      5236\n",
      "weighted avg       0.97      0.97      0.95      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5149\n",
      "           1       0.00      0.00      0.00        87\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.49      0.50      0.50      5236\n",
      "weighted avg       0.97      0.98      0.98      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5080\n",
      "           1       0.00      0.00      0.00       156\n",
      "\n",
      "    accuracy                           0.97      5236\n",
      "   macro avg       0.49      0.50      0.49      5236\n",
      "weighted avg       0.94      0.97      0.96      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5236\n",
      "\n",
      "    accuracy                           1.00      5236\n",
      "   macro avg       1.00      1.00      1.00      5236\n",
      "weighted avg       1.00      1.00      1.00      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4908\n",
      "           1       0.50      0.02      0.05       328\n",
      "\n",
      "    accuracy                           0.94      5236\n",
      "   macro avg       0.72      0.51      0.51      5236\n",
      "weighted avg       0.91      0.94      0.91      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4624\n",
      "           1       0.74      0.06      0.11       612\n",
      "\n",
      "    accuracy                           0.89      5236\n",
      "   macro avg       0.81      0.53      0.53      5236\n",
      "weighted avg       0.87      0.89      0.84      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4786\n",
      "           1       0.71      0.04      0.07       450\n",
      "\n",
      "    accuracy                           0.92      5236\n",
      "   macro avg       0.81      0.52      0.51      5236\n",
      "weighted avg       0.90      0.92      0.88      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5156\n",
      "           1       0.71      0.06      0.11        80\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.85      0.53      0.55      5236\n",
      "weighted avg       0.98      0.99      0.98      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5120\n",
      "           1       0.50      0.01      0.02       116\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.74      0.50      0.50      5236\n",
      "weighted avg       0.97      0.98      0.97      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5171\n",
      "           1       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.49      0.50      0.50      5236\n",
      "weighted avg       0.98      0.99      0.98      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5053\n",
      "           1       0.00      0.00      0.00       183\n",
      "\n",
      "    accuracy                           0.96      5236\n",
      "   macro avg       0.48      0.50      0.49      5236\n",
      "weighted avg       0.93      0.96      0.95      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5000\n",
      "           1       0.89      0.03      0.07       236\n",
      "\n",
      "    accuracy                           0.96      5236\n",
      "   macro avg       0.92      0.52      0.52      5236\n",
      "weighted avg       0.95      0.96      0.94      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      4522\n",
      "           1       0.35      0.01      0.02       714\n",
      "\n",
      "    accuracy                           0.86      5236\n",
      "   macro avg       0.61      0.50      0.47      5236\n",
      "weighted avg       0.79      0.86      0.80      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4906\n",
      "           1       0.00      0.00      0.00       330\n",
      "\n",
      "    accuracy                           0.94      5236\n",
      "   macro avg       0.47      0.50      0.48      5236\n",
      "weighted avg       0.88      0.94      0.91      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4981\n",
      "           1       0.00      0.00      0.00       255\n",
      "\n",
      "    accuracy                           0.95      5236\n",
      "   macro avg       0.48      0.50      0.49      5236\n",
      "weighted avg       0.90      0.95      0.93      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4987\n",
      "           1       0.67      0.02      0.03       249\n",
      "\n",
      "    accuracy                           0.95      5236\n",
      "   macro avg       0.81      0.51      0.50      5236\n",
      "weighted avg       0.94      0.95      0.93      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5129\n",
      "           1       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.49      0.50      0.49      5236\n",
      "weighted avg       0.96      0.98      0.97      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5203\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.99      0.99      0.99      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5185\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.98      0.99      0.99      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5218\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           1.00      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.99      1.00      0.99      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5167\n",
      "           1       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.49      0.50      0.50      5236\n",
      "weighted avg       0.97      0.99      0.98      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5013\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           0.96      5236\n",
      "   macro avg       0.48      0.50      0.49      5236\n",
      "weighted avg       0.92      0.96      0.94      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85      3800\n",
      "           1       0.86      0.06      0.11      1436\n",
      "\n",
      "    accuracy                           0.74      5236\n",
      "   macro avg       0.80      0.53      0.48      5236\n",
      "weighted avg       0.77      0.74      0.64      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4804\n",
      "           1       1.00      0.00      0.00       432\n",
      "\n",
      "    accuracy                           0.92      5236\n",
      "   macro avg       0.96      0.50      0.48      5236\n",
      "weighted avg       0.92      0.92      0.88      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4741\n",
      "           1       0.78      0.01      0.03       495\n",
      "\n",
      "    accuracy                           0.91      5236\n",
      "   macro avg       0.84      0.51      0.49      5236\n",
      "weighted avg       0.89      0.91      0.86      5236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5181\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.49      0.50      0.50      5236\n",
      "weighted avg       0.98      0.99      0.98      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4774\n",
      "           1       0.84      0.15      0.25       462\n",
      "\n",
      "    accuracy                           0.92      5236\n",
      "   macro avg       0.88      0.57      0.60      5236\n",
      "weighted avg       0.92      0.92      0.90      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5141\n",
      "           1       1.00      0.02      0.04        95\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.99      0.51      0.52      5236\n",
      "weighted avg       0.98      0.98      0.97      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4966\n",
      "           1       0.50      0.00      0.01       270\n",
      "\n",
      "    accuracy                           0.95      5236\n",
      "   macro avg       0.72      0.50      0.49      5236\n",
      "weighted avg       0.93      0.95      0.92      5236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      4270\n",
      "           1       0.73      0.07      0.12       966\n",
      "\n",
      "    accuracy                           0.82      5236\n",
      "   macro avg       0.78      0.53      0.51      5236\n",
      "weighted avg       0.81      0.82      0.76      5236\n",
      "\n",
      "Trained model saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    ''' Performs a series of operations to build a pipeline-based model fitted and tested with information contained in the database file contained in database_filepath,\n",
    "        evaluates the model and stores the model in the path defined by model_filepath\n",
    "    \n",
    "    INPUT:\n",
    "    database_filepath - path of the .db file (database) created and stored by the process_data.py script \n",
    "    model_filepath - path where model will be saved\n",
    "    '''\n",
    "    \n",
    "    #if len(sys.argv) == 3:\n",
    "#database_filepath, model_filepath = sys.argv[1:]\n",
    "#print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "X, Y, category_names = load_data()#database_filepath)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print('Building model...')\n",
    "model = build_model()\n",
    "\n",
    "print('Training model...')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "#print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model)\n",
    "\n",
    "print('Trained model saved!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
