{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\John\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "import sqlite3\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_data():#database_filepath):\n",
    "    \n",
    "    ''' Load a database and provides attribute variable, target variables and headers corresponding to target variables\n",
    "    \n",
    "    INPUT:\n",
    "    database_filepath - path of the .db file (database) created and stored by the process_data.py script\n",
    "   \n",
    "    \n",
    "    OUTPUT:\n",
    "    X - dataframe corresponding to the attribute variable (1 column, that corresponds to the text contained in the disaster_message.csv file which is input of the process_data.py script)\n",
    "    Y - dataframe corresponding to the target variables (36 columns, correspond to each value of the \"categories\" column contained in the categories_message.csv file which is input of the                     process_data.py script) \n",
    "    category_names - headers of the Y dataframe\n",
    "    '''\n",
    "    #to run on a locally\n",
    "    conn = sqlite3.connect('DisasterResponse.db')\n",
    "\n",
    "    df=pd.read_sql('SELECT * FROM DisasterResponse', conn)\n",
    "    \n",
    "    #run at prompt\n",
    "    #engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "   \n",
    "    #df = pd.read_sql_table('DisasterResponseTable', engine) \n",
    "    \n",
    "    df = df.replace(to_replace='None', value=np.nan)\n",
    "    \n",
    "    df=df[df[\"message\"]!='#NAME?']\n",
    "    \n",
    "    #X = df[\"message\"]\n",
    "    X = pd.Series(df['message'])\n",
    "    Y = df.drop(['id','message','original','genre'], axis=1)\n",
    "    \n",
    "    category_names = Y.columns\n",
    "    \n",
    "    return X, Y, category_names\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, category_names =load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4    says: west side of Haiti, rest of the country ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    ''' Tokenizes and normalizes the input text, removes stop words and symbols apart from letters and numbers\n",
    "    \n",
    "    INPUT:\n",
    "    df- a text (string format)\n",
    "      \n",
    "    \n",
    "    OUTPUT:\n",
    "    clear tokens- a list of strings, obtained as a result of the following operations on the input text:\n",
    "            - Everything but letters (uppercase und lowercase) and numbers will be removed\n",
    "            - Text will be divided into separate elements, or \"tokens\"\n",
    "            - Stop words corresponding to the English language will be removed\n",
    "            - Tokens will be lemmatized, i.e. tokens will be converted into \"root words\",\n",
    "                based on WordNetLemmatizer\n",
    "            - Tokens will be lemmatized, i.e. tokens will be converted into \"root words\"\n",
    "            - Tokens will be normalized\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    # normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text)\n",
    "   \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # remove tokens corresponding to stop words\n",
    "    tokens = [word for word in tokens if not word in stopwords.words(\"english\")]\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # iterate through each token\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        \n",
    "        # lemmatize, normalize case, and remove leading/trailing white space\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens \n",
    "    \n",
    "    #pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    '''  Builds a pipeline model\n",
    "    \n",
    "    OUTPUT:\n",
    "    model_pipeline - A pipeline-based model with the following characteristics:\n",
    "            - makes use of \"CountVectorizer\" as vectorizer\n",
    "            - makes use of \"TfidfTransformer\" as transformer\n",
    "            - makes use of \"MultiOutputClassifier\", subtype \"RandomForestClassifier\", as classifier\n",
    "            - makes use of GridSearchCV in order to find the optimal combination of differemt hyperparameters\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(KNeighborsClassifier()))    ])\n",
    "    \n",
    "    parameters = {\n",
    "    \n",
    "       'vect__ngram_range': [(1, 1)],\n",
    "    \n",
    "       'vect__max_df': [0.5],\n",
    "       'vect__max_features': [None],\n",
    "\n",
    "       'clf__estimator__n_neighbors': [2]\n",
    "                } \n",
    "    \n",
    "    \n",
    "    cv = GridSearchCV(pipeline, parameters,verbose=3)\n",
    "    #print(cv)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, model):\n",
    "    \n",
    "    ''' Fits the model with the train components of X and Y\n",
    "    \n",
    "    INPUT:\n",
    "    X_train - train component of the dataframe corresponding to the attribute variable\n",
    "    y_train - train component of the dataframe corresponding to the target variable\n",
    "    model - mathematical model that will be fitted with the train components of attribute variable X and target attribute y\n",
    "   \n",
    "    OUTPUT:\n",
    "    model - mathematical model that was inserted as input of the function, already fitted with X_test and y_test   \n",
    "   \n",
    "    '''\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(cv, X_test, y_test, category_names):    \n",
    "    \n",
    "    ''' Evaluates the model, providing the test_score by using ClassificationReport (useful for multi-target models)\n",
    "    \n",
    "    INPUT:\n",
    "    model - mathematical model that was already fitted with X_test and y_test in the train function \n",
    "    X_test - dataframe that corresponds to the train component of the attribute variable X\n",
    "    y_test - contains the train component of the target variable yy - dataframe corresponding to the target variable; will be divided into train ant test sets\n",
    " \n",
    "   \n",
    "    '''    \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # y_test_pred and y_train_pred are obtaines as numpy arrays\n",
    "    # for further operations, we need to convert them into dataframe\n",
    "    # therefore, y_test_pred_df and y_train_pred_df are introduced:\n",
    "\n",
    "    y_headers = y_test.columns\n",
    "\n",
    "    y_test_pred_df = pd.DataFrame(y_test_pred, columns = y_headers)\n",
    "    #print(y_test_pred_df)\n",
    "    \n",
    "    for col in y_test:\n",
    "        #print(y_test_pred_df[col])#added as a test feature to print out the column as the test.\n",
    "        #need to extract the col name\n",
    "        print(\"Test Score results for Category..........\",col)\n",
    "        #print(y_headers[col])\n",
    "        test_score = classification_report(y_test[col],y_test_pred_df[col])\n",
    "        #print(\"\\nBest Parameters:\", cv.best_params_)\n",
    "        print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    \n",
    "    ''' Saves the model as a pickle file\n",
    "    \n",
    "    INPUT:\n",
    "    model - mathematical model that was already fitted with X_test and y_test in the train function \n",
    "    model_filepath - path where model will be saved\n",
    "   \n",
    "    '''       \n",
    "    \n",
    "    #pkl_filename = '{}'.format(model_filepath)\n",
    "    #with open(pkl_model, 'wb') as file:\n",
    "        #pickle.dump(model, file)\n",
    "    filename = 'classifier.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Training model...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), score=0.258, total= 5.5min\n",
      "[CV] clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), score=0.259, total= 5.8min\n",
      "[CV] clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 11.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), score=0.262, total= 5.7min\n",
      "[CV] clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), score=0.263, total= 5.3min\n",
      "[CV] clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1) \n",
      "[CV]  clf__estimator__n_neighbors=2, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), score=0.272, total= 5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 27.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Test Score results for Category.......... related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.53      0.47      1181\n",
      "           1       0.85      0.78      0.82      4017\n",
      "\n",
      "    accuracy                           0.73      5198\n",
      "   macro avg       0.63      0.66      0.64      5198\n",
      "weighted avg       0.75      0.73      0.74      5198\n",
      "\n",
      "Test Score results for Category.......... request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91      4340\n",
      "           1       0.72      0.10      0.17       858\n",
      "\n",
      "    accuracy                           0.84      5198\n",
      "   macro avg       0.78      0.54      0.54      5198\n",
      "weighted avg       0.83      0.84      0.79      5198\n",
      "\n",
      "Test Score results for Category.......... offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5175\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           1.00      5198\n",
      "   macro avg       0.50      0.50      0.50      5198\n",
      "weighted avg       0.99      1.00      0.99      5198\n",
      "\n",
      "Test Score results for Category.......... aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74      3032\n",
      "           1       0.70      0.04      0.08      2166\n",
      "\n",
      "    accuracy                           0.59      5198\n",
      "   macro avg       0.64      0.51      0.41      5198\n",
      "weighted avg       0.63      0.59      0.46      5198\n",
      "\n",
      "Test Score results for Category.......... medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4763\n",
      "           1       1.00      0.00      0.00       435\n",
      "\n",
      "    accuracy                           0.92      5198\n",
      "   macro avg       0.96      0.50      0.48      5198\n",
      "weighted avg       0.92      0.92      0.88      5198\n",
      "\n",
      "Test Score results for Category.......... medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4945\n",
      "           1       1.00      0.02      0.04       253\n",
      "\n",
      "    accuracy                           0.95      5198\n",
      "   macro avg       0.98      0.51      0.51      5198\n",
      "weighted avg       0.95      0.95      0.93      5198\n",
      "\n",
      "Test Score results for Category.......... search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5056\n",
      "           1       0.00      0.00      0.00       142\n",
      "\n",
      "    accuracy                           0.97      5198\n",
      "   macro avg       0.49      0.50      0.49      5198\n",
      "weighted avg       0.95      0.97      0.96      5198\n",
      "\n",
      "Test Score results for Category.......... security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5108\n",
      "           1       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.98      5198\n",
      "   macro avg       0.49      0.50      0.50      5198\n",
      "weighted avg       0.97      0.98      0.97      5198\n",
      "\n",
      "Test Score results for Category.......... military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5024\n",
      "           1       0.00      0.00      0.00       174\n",
      "\n",
      "    accuracy                           0.97      5198\n",
      "   macro avg       0.48      0.50      0.49      5198\n",
      "weighted avg       0.93      0.97      0.95      5198\n",
      "\n",
      "Test Score results for Category.......... child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5198\n",
      "\n",
      "    accuracy                           1.00      5198\n",
      "   macro avg       1.00      1.00      1.00      5198\n",
      "weighted avg       1.00      1.00      1.00      5198\n",
      "\n",
      "Test Score results for Category.......... water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4880\n",
      "           1       0.92      0.03      0.07       318\n",
      "\n",
      "    accuracy                           0.94      5198\n",
      "   macro avg       0.93      0.52      0.52      5198\n",
      "weighted avg       0.94      0.94      0.91      5198\n",
      "\n",
      "Test Score results for Category.......... food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      4621\n",
      "           1       0.79      0.08      0.14       577\n",
      "\n",
      "    accuracy                           0.90      5198\n",
      "   macro avg       0.84      0.54      0.54      5198\n",
      "weighted avg       0.89      0.90      0.86      5198\n",
      "\n",
      "Test Score results for Category.......... shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4752\n",
      "           1       0.59      0.02      0.04       446\n",
      "\n",
      "    accuracy                           0.91      5198\n",
      "   macro avg       0.75      0.51      0.50      5198\n",
      "weighted avg       0.89      0.91      0.88      5198\n",
      "\n",
      "Test Score results for Category.......... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5121\n",
      "           1       1.00      0.04      0.08        77\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.52      0.53      5198\n",
      "weighted avg       0.99      0.99      0.98      5198\n",
      "\n",
      "Test Score results for Category.......... money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5080\n",
      "           1       1.00      0.01      0.02       118\n",
      "\n",
      "    accuracy                           0.98      5198\n",
      "   macro avg       0.99      0.50      0.50      5198\n",
      "weighted avg       0.98      0.98      0.97      5198\n",
      "\n",
      "Test Score results for Category.......... missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5133\n",
      "           1       1.00      0.02      0.03        65\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.99      0.51      0.51      5198\n",
      "weighted avg       0.99      0.99      0.98      5198\n",
      "\n",
      "Test Score results for Category.......... refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5020\n",
      "           1       0.00      0.00      0.00       178\n",
      "\n",
      "    accuracy                           0.97      5198\n",
      "   macro avg       0.48      0.50      0.49      5198\n",
      "weighted avg       0.93      0.97      0.95      5198\n",
      "\n",
      "Test Score results for Category.......... death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4960\n",
      "           1       0.67      0.03      0.05       238\n",
      "\n",
      "    accuracy                           0.95      5198\n",
      "   macro avg       0.81      0.51      0.51      5198\n",
      "weighted avg       0.94      0.95      0.93      5198\n",
      "\n",
      "Test Score results for Category.......... other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4496\n",
      "           1       0.30      0.01      0.02       702\n",
      "\n",
      "    accuracy                           0.86      5198\n",
      "   macro avg       0.58      0.50      0.47      5198\n",
      "weighted avg       0.79      0.86      0.80      5198\n",
      "\n",
      "Test Score results for Category.......... infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4833\n",
      "           1       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.93      5198\n",
      "   macro avg       0.46      0.50      0.48      5198\n",
      "weighted avg       0.86      0.93      0.90      5198\n",
      "\n",
      "Test Score results for Category.......... transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4920\n",
      "           1       0.00      0.00      0.00       278\n",
      "\n",
      "    accuracy                           0.95      5198\n",
      "   macro avg       0.47      0.50      0.49      5198\n",
      "weighted avg       0.90      0.95      0.92      5198\n",
      "\n",
      "Test Score results for Category.......... buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4912\n",
      "           1       1.00      0.01      0.03       286\n",
      "\n",
      "    accuracy                           0.95      5198\n",
      "   macro avg       0.97      0.51      0.50      5198\n",
      "weighted avg       0.95      0.95      0.92      5198\n",
      "\n",
      "Test Score results for Category.......... electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5093\n",
      "           1       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.98      5198\n",
      "   macro avg       0.49      0.50      0.49      5198\n",
      "weighted avg       0.96      0.98      0.97      5198\n",
      "\n",
      "Test Score results for Category.......... tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5174\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           1.00      5198\n",
      "   macro avg       0.50      0.50      0.50      5198\n",
      "weighted avg       0.99      1.00      0.99      5198\n",
      "\n",
      "Test Score results for Category.......... hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5143\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.49      0.50      0.50      5198\n",
      "weighted avg       0.98      0.99      0.98      5198\n",
      "\n",
      "Test Score results for Category.......... shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5173\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           1.00      5198\n",
      "   macro avg       0.50      0.50      0.50      5198\n",
      "weighted avg       0.99      1.00      0.99      5198\n",
      "\n",
      "Test Score results for Category.......... aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5132\n",
      "           1       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.49      0.50      0.50      5198\n",
      "weighted avg       0.97      0.99      0.98      5198\n",
      "\n",
      "Test Score results for Category.......... other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4943\n",
      "           1       0.00      0.00      0.00       255\n",
      "\n",
      "    accuracy                           0.95      5198\n",
      "   macro avg       0.48      0.50      0.49      5198\n",
      "weighted avg       0.90      0.95      0.93      5198\n",
      "\n",
      "Test Score results for Category.......... weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      3709\n",
      "           1       0.82      0.06      0.10      1489\n",
      "\n",
      "    accuracy                           0.73      5198\n",
      "   macro avg       0.77      0.53      0.47      5198\n",
      "weighted avg       0.75      0.73      0.63      5198\n",
      "\n",
      "Test Score results for Category.......... floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4739\n",
      "           1       1.00      0.01      0.01       459\n",
      "\n",
      "    accuracy                           0.91      5198\n",
      "   macro avg       0.96      0.50      0.48      5198\n",
      "weighted avg       0.92      0.91      0.87      5198\n",
      "\n",
      "Test Score results for Category.......... storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4692\n",
      "           1       0.60      0.01      0.01       506\n",
      "\n",
      "    accuracy                           0.90      5198\n",
      "   macro avg       0.75      0.50      0.48      5198\n",
      "weighted avg       0.87      0.90      0.86      5198\n",
      "\n",
      "Test Score results for Category.......... fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5149\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.99      5198\n",
      "   macro avg       0.50      0.50      0.50      5198\n",
      "weighted avg       0.98      0.99      0.99      5198\n",
      "\n",
      "Test Score results for Category.......... earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4713\n",
      "           1       0.82      0.14      0.25       485\n",
      "\n",
      "    accuracy                           0.92      5198\n",
      "   macro avg       0.87      0.57      0.60      5198\n",
      "weighted avg       0.91      0.92      0.89      5198\n",
      "\n",
      "Test Score results for Category.......... cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5101\n",
      "           1       0.00      0.00      0.00        97\n",
      "\n",
      "    accuracy                           0.98      5198\n",
      "   macro avg       0.49      0.50      0.50      5198\n",
      "weighted avg       0.96      0.98      0.97      5198\n",
      "\n",
      "Test Score results for Category.......... other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4910\n",
      "           1       0.80      0.01      0.03       288\n",
      "\n",
      "    accuracy                           0.95      5198\n",
      "   macro avg       0.87      0.51      0.50      5198\n",
      "weighted avg       0.94      0.95      0.92      5198\n",
      "\n",
      "Test Score results for Category.......... direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      4207\n",
      "           1       0.73      0.07      0.13       991\n",
      "\n",
      "    accuracy                           0.82      5198\n",
      "   macro avg       0.77      0.53      0.51      5198\n",
      "weighted avg       0.80      0.82      0.75      5198\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-408f769900b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Saving model...\\n    MODEL: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_filepath' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    ''' Performs a series of operations to build a pipeline-based model fitted and tested with information contained in the database file contained in database_filepath,\n",
    "        evaluates the model and stores the model in the path defined by model_filepath\n",
    "    \n",
    "    INPUT:\n",
    "    database_filepath - path of the .db file (database) created and stored by the process_data.py script \n",
    "    model_filepath - path where model will be saved\n",
    "    '''\n",
    "    \n",
    "    #if len(sys.argv) == 3:\n",
    "#database_filepath, model_filepath = sys.argv[1:]\n",
    "#print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "X, Y, category_names = load_data()#database_filepath)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print('Building model...')\n",
    "model = build_model()\n",
    "\n",
    "print('Training model...')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model)\n",
    "\n",
    "print('Trained model saved!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(category_names)\n",
    "for i in category_names:\n",
    "    print(category_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # y_test_pred and y_train_pred are obtaines as numpy arrays\n",
    "    # for further operations, we need to convert them into dataframe\n",
    "    # therefore, y_test_pred_df and y_train_pred_df are introduced:\n",
    "\n",
    "y_headers = y_test.columns\n",
    "\n",
    "\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred, columns = y_headers)\n",
    "print(y_test_pred_df)\n",
    "for col in y_test:\n",
    "    print(y_test_pred_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(category_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(category_names)):\n",
    "    print(category_names[i])\n",
    "    p=i+2\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_headers = Y_test.columns\n",
    "\n",
    "print(\"Results for Category\",y_headers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_test_pred_df = pd.DataFrame(y_test_pred, columns = y_headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
