{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\jringros\\AppData\\Loc\n",
      "[nltk_data]     al\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\jringros\\AppData\\L\n",
      "[nltk_data]     ocal\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\jringros\\AppData\n",
      "[nltk_data]     \\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\nltk_da\n",
      "[nltk_data]     ta...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "import sqlite3\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_data():#database_filepath):\n",
    "    \n",
    "    ''' Load a database and provides attribute variable, target variables and headers corresponding to target variables\n",
    "    \n",
    "    INPUT:\n",
    "    database_filepath - path of the .db file (database) created and stored by the process_data.py script\n",
    "   \n",
    "    \n",
    "    OUTPUT:\n",
    "    X - dataframe corresponding to the attribute variable (1 column, that corresponds to the text contained in the disaster_message.csv file which is input of the process_data.py script)\n",
    "    Y - dataframe corresponding to the target variables (36 columns, correspond to each value of the \"categories\" column contained in the categories_message.csv file which is input of the                     process_data.py script) \n",
    "    category_names - headers of the Y dataframe\n",
    "    '''\n",
    "    #to run on a locally\n",
    "    conn = sqlite3.connect('messages.db')\n",
    "\n",
    "    df=pd.read_sql('SELECT * FROM messages', conn)\n",
    "    \n",
    "    #run at prompt\n",
    "    #engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "   \n",
    "    #df = pd.read_sql_table('DisasterResponseTable', engine) \n",
    "    \n",
    "    df = df.replace(to_replace='None', value=np.nan)\n",
    "    \n",
    "    df=df[df[\"message\"]!='#NAME?']\n",
    "    \n",
    "    #X = df[\"message\"]\n",
    "    X = pd.Series(df['message'])\n",
    "    Y = df.drop(['id','message','original','genre'], axis=1)\n",
    "    \n",
    "    category_names = Y.columns\n",
    "    \n",
    "    return X, Y, category_names\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, category_names =load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4    says: west side of Haiti, rest of the country ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    ''' Tokenizes and normalizes the input text, removes stop words and symbols apart from letters and numbers\n",
    "    \n",
    "    INPUT:\n",
    "    df- a text (string format)\n",
    "      \n",
    "    \n",
    "    OUTPUT:\n",
    "    clear tokens- a list of strings, obtained as a result of the following operations on the input text:\n",
    "            - Everything but letters (uppercase und lowercase) and numbers will be removed\n",
    "            - Text will be divided into separate elements, or \"tokens\"\n",
    "            - Stop words corresponding to the English language will be removed\n",
    "            - Tokens will be lemmatized, i.e. tokens will be converted into \"root words\",\n",
    "                based on WordNetLemmatizer\n",
    "            - Tokens will be lemmatized, i.e. tokens will be converted into \"root words\"\n",
    "            - Tokens will be normalized\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    # normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text)\n",
    "   \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # remove tokens corresponding to stop words\n",
    "    tokens = [word for word in tokens if not word in stopwords.words(\"english\")]\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # iterate through each token\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        \n",
    "        # lemmatize, normalize case, and remove leading/trailing white space\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens \n",
    "    \n",
    "    #pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    '''  Builds a pipeline model\n",
    "    \n",
    "    OUTPUT:\n",
    "    model_pipeline - A pipeline-based model with the following characteristics:\n",
    "            - makes use of \"CountVectorizer\" as vectorizer\n",
    "            - makes use of \"TfidfTransformer\" as transformer\n",
    "            - makes use of \"MultiOutputClassifier\", subtype \"RandomForestClassifier\", as classifier\n",
    "            - makes use of GridSearchCV in order to find the optimal combination of differemt hyperparameters\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(KNeighborsClassifier()))    ])\n",
    "    \n",
    "    parameters = {\n",
    "    \n",
    "       'vect__ngram_range': [(1, 1)],\n",
    "    \n",
    "       'vect__max_df': [0.5],\n",
    "       'vect__max_features': [None],\n",
    "\n",
    "       'clf__estimator__n_neighbors': [2]\n",
    "                } \n",
    "    \n",
    "    \n",
    "    cv = GridSearchCV(pipeline, parameters,verbose=3)\n",
    "    #print(cv)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, model):\n",
    "    \n",
    "    ''' Fits the model with the train components of X and Y\n",
    "    \n",
    "    INPUT:\n",
    "    X_train - train component of the dataframe corresponding to the attribute variable\n",
    "    y_train - train component of the dataframe corresponding to the target variable\n",
    "    model - mathematical model that will be fitted with the train components of attribute variable X and target attribute y\n",
    "   \n",
    "    OUTPUT:\n",
    "    model - mathematical model that was inserted as input of the function, already fitted with X_test and y_test   \n",
    "   \n",
    "    '''\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(cv, X_test, y_test, category_names):    \n",
    "    \n",
    "    ''' Evaluates the model, providing the test_score by using ClassificationReport (useful for multi-target models)\n",
    "    \n",
    "    INPUT:\n",
    "    model - mathematical model that was already fitted with X_test and y_test in the train function \n",
    "    X_test - dataframe that corresponds to the train component of the attribute variable X\n",
    "    y_test - contains the train component of the target variable yy - dataframe corresponding to the target variable; will be divided into train ant test sets\n",
    " \n",
    "   \n",
    "    '''    \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # y_test_pred and y_train_pred are obtaines as numpy arrays\n",
    "    # for further operations, we need to convert them into dataframe\n",
    "    # therefore, y_test_pred_df and y_train_pred_df are introduced:\n",
    "\n",
    "    y_headers = y_test.columns\n",
    "\n",
    "    y_test_pred_df = pd.DataFrame(y_test_pred, columns = y_headers)\n",
    "    #print(y_test_pred_df)\n",
    "    \n",
    "    for col in y_test:\n",
    "        #print(y_test_pred_df[col])#added as a test feature to print out the column as the test.\n",
    "        #need to extract the col name\n",
    "        print(\"Test Score results for Category..........\",col)\n",
    "        #print(y_headers[col])\n",
    "        test_score = classification_report(y_test[col],y_test_pred_df[col])\n",
    "        #print(\"\\nBest Parameters:\", cv.best_params_)\n",
    "        print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    \n",
    "    ''' Saves the model as a pickle file\n",
    "    \n",
    "    INPUT:\n",
    "    model - mathematical model that was already fitted with X_test and y_test in the train function \n",
    "    model_filepath - path where model will be saved\n",
    "   \n",
    "    '''       \n",
    "    \n",
    "    #pkl_filename = '{}'.format(model_filepath)\n",
    "    #with open(pkl_model, 'wb') as file:\n",
    "        #pickle.dump(model, file)\n",
    "    filename = 'classifier.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Test Score results for Category.......... ('related',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.24      0.35      1263\n",
      "           1       0.86      0.15      0.26      3934\n",
      "           2       0.01      0.85      0.02        39\n",
      "\n",
      "    accuracy                           0.18      5236\n",
      "   macro avg       0.49      0.41      0.21      5236\n",
      "weighted avg       0.79      0.18      0.28      5236\n",
      "\n",
      "Test Score results for Category.......... ('request',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      4346\n",
      "           1       0.79      0.10      0.17       890\n",
      "\n",
      "    accuracy                           0.84      5236\n",
      "   macro avg       0.82      0.55      0.54      5236\n",
      "weighted avg       0.83      0.84      0.79      5236\n",
      "\n",
      "Test Score results for Category.......... ('offer',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5216\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           1.00      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.99      1.00      0.99      5236\n",
      "\n",
      "Test Score results for Category.......... ('aid_related',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75      3107\n",
      "           1       0.79      0.05      0.09      2129\n",
      "\n",
      "    accuracy                           0.61      5236\n",
      "   macro avg       0.69      0.52      0.42      5236\n",
      "weighted avg       0.68      0.61      0.48      5236\n",
      "\n",
      "Test Score results for Category.......... ('medical_help',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4859\n",
      "           1       0.00      0.00      0.00       377\n",
      "\n",
      "    accuracy                           0.93      5236\n",
      "   macro avg       0.46      0.50      0.48      5236\n",
      "weighted avg       0.86      0.93      0.89      5236\n",
      "\n",
      "Test Score results for Category.......... ('medical_products',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4989\n",
      "           1       0.67      0.01      0.02       247\n",
      "\n",
      "    accuracy                           0.95      5236\n",
      "   macro avg       0.81      0.50      0.50      5236\n",
      "weighted avg       0.94      0.95      0.93      5236\n",
      "\n",
      "Test Score results for Category.......... ('search_and_rescue',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5095\n",
      "           1       1.00      0.01      0.01       141\n",
      "\n",
      "    accuracy                           0.97      5236\n",
      "   macro avg       0.99      0.50      0.50      5236\n",
      "weighted avg       0.97      0.97      0.96      5236\n",
      "\n",
      "Test Score results for Category.......... ('security',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5149\n",
      "           1       0.00      0.00      0.00        87\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.49      0.50      0.50      5236\n",
      "weighted avg       0.97      0.98      0.98      5236\n",
      "\n",
      "Test Score results for Category.......... ('military',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5053\n",
      "           1       0.00      0.00      0.00       183\n",
      "\n",
      "    accuracy                           0.97      5236\n",
      "   macro avg       0.48      0.50      0.49      5236\n",
      "weighted avg       0.93      0.97      0.95      5236\n",
      "\n",
      "Test Score results for Category.......... ('child_alone',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5236\n",
      "\n",
      "    accuracy                           1.00      5236\n",
      "   macro avg       1.00      1.00      1.00      5236\n",
      "weighted avg       1.00      1.00      1.00      5236\n",
      "\n",
      "Test Score results for Category.......... ('water',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4908\n",
      "           1       0.72      0.04      0.08       328\n",
      "\n",
      "    accuracy                           0.94      5236\n",
      "   macro avg       0.83      0.52      0.52      5236\n",
      "weighted avg       0.93      0.94      0.91      5236\n",
      "\n",
      "Test Score results for Category.......... ('food',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4667\n",
      "           1       0.77      0.07      0.13       569\n",
      "\n",
      "    accuracy                           0.90      5236\n",
      "   macro avg       0.84      0.53      0.54      5236\n",
      "weighted avg       0.88      0.90      0.86      5236\n",
      "\n",
      "Test Score results for Category.......... ('shelter',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4794\n",
      "           1       0.65      0.02      0.05       442\n",
      "\n",
      "    accuracy                           0.92      5236\n",
      "   macro avg       0.78      0.51      0.50      5236\n",
      "weighted avg       0.89      0.92      0.88      5236\n",
      "\n",
      "Test Score results for Category.......... ('clothing',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5168\n",
      "           1       0.43      0.04      0.08        68\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.71      0.52      0.54      5236\n",
      "weighted avg       0.98      0.99      0.98      5236\n",
      "\n",
      "Test Score results for Category.......... ('money',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5117\n",
      "           1       1.00      0.02      0.03       119\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.99      0.51      0.51      5236\n",
      "weighted avg       0.98      0.98      0.97      5236\n",
      "\n",
      "Test Score results for Category.......... ('missing_people',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5175\n",
      "           1       1.00      0.02      0.03        61\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.99      0.51      0.51      5236\n",
      "weighted avg       0.99      0.99      0.98      5236\n",
      "\n",
      "Test Score results for Category.......... ('refugees',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5074\n",
      "           1       0.00      0.00      0.00       162\n",
      "\n",
      "    accuracy                           0.97      5236\n",
      "   macro avg       0.48      0.50      0.49      5236\n",
      "weighted avg       0.94      0.97      0.95      5236\n",
      "\n",
      "Test Score results for Category.......... ('death',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5027\n",
      "           1       1.00      0.01      0.02       209\n",
      "\n",
      "    accuracy                           0.96      5236\n",
      "   macro avg       0.98      0.50      0.50      5236\n",
      "weighted avg       0.96      0.96      0.94      5236\n",
      "\n",
      "Test Score results for Category.......... ('other_aid',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4529\n",
      "           1       0.33      0.01      0.02       707\n",
      "\n",
      "    accuracy                           0.86      5236\n",
      "   macro avg       0.60      0.50      0.47      5236\n",
      "weighted avg       0.79      0.86      0.80      5236\n",
      "\n",
      "Test Score results for Category.......... ('infrastructure_related',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4901\n",
      "           1       0.00      0.00      0.00       335\n",
      "\n",
      "    accuracy                           0.94      5236\n",
      "   macro avg       0.47      0.50      0.48      5236\n",
      "weighted avg       0.88      0.94      0.91      5236\n",
      "\n",
      "Test Score results for Category.......... ('transport',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5018\n",
      "           1       0.00      0.00      0.00       218\n",
      "\n",
      "    accuracy                           0.96      5236\n",
      "   macro avg       0.48      0.50      0.49      5236\n",
      "weighted avg       0.92      0.96      0.94      5236\n",
      "\n",
      "Test Score results for Category.......... ('buildings',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4979\n",
      "           1       1.00      0.01      0.02       257\n",
      "\n",
      "    accuracy                           0.95      5236\n",
      "   macro avg       0.98      0.50      0.50      5236\n",
      "weighted avg       0.95      0.95      0.93      5236\n",
      "\n",
      "Test Score results for Category.......... ('electricity',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5129\n",
      "           1       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.49      0.50      0.49      5236\n",
      "weighted avg       0.96      0.98      0.97      5236\n",
      "\n",
      "Test Score results for Category.......... ('tools',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5202\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.99      0.99      0.99      5236\n",
      "\n",
      "Test Score results for Category.......... ('hospitals',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5182\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.49      0.50      0.50      5236\n",
      "weighted avg       0.98      0.99      0.98      5236\n",
      "\n",
      "Test Score results for Category.......... ('shops',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5204\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.99      0.99      0.99      5236\n",
      "\n",
      "Test Score results for Category.......... ('aid_centers',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5184\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.98      0.99      0.99      5236\n",
      "\n",
      "Test Score results for Category.......... ('other_infrastructure',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5005\n",
      "           1       0.00      0.00      0.00       231\n",
      "\n",
      "    accuracy                           0.96      5236\n",
      "   macro avg       0.48      0.50      0.49      5236\n",
      "weighted avg       0.91      0.96      0.93      5236\n",
      "\n",
      "Test Score results for Category.......... ('weather_related',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85      3804\n",
      "           1       0.83      0.06      0.11      1432\n",
      "\n",
      "    accuracy                           0.74      5236\n",
      "   macro avg       0.78      0.53      0.48      5236\n",
      "weighted avg       0.76      0.74      0.65      5236\n",
      "\n",
      "Test Score results for Category.......... ('floods',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4862\n",
      "           1       0.67      0.01      0.01       374\n",
      "\n",
      "    accuracy                           0.93      5236\n",
      "   macro avg       0.80      0.50      0.49      5236\n",
      "weighted avg       0.91      0.93      0.90      5236\n",
      "\n",
      "Test Score results for Category.......... ('storm',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4743\n",
      "           1       0.38      0.01      0.01       493\n",
      "\n",
      "    accuracy                           0.91      5236\n",
      "   macro avg       0.64      0.50      0.48      5236\n",
      "weighted avg       0.86      0.91      0.86      5236\n",
      "\n",
      "Test Score results for Category.......... ('fire',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5186\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.99      5236\n",
      "   macro avg       0.50      0.50      0.50      5236\n",
      "weighted avg       0.98      0.99      0.99      5236\n",
      "\n",
      "Test Score results for Category.......... ('earthquake',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4740\n",
      "           1       0.86      0.15      0.26       496\n",
      "\n",
      "    accuracy                           0.92      5236\n",
      "   macro avg       0.89      0.58      0.61      5236\n",
      "weighted avg       0.91      0.92      0.89      5236\n",
      "\n",
      "Test Score results for Category.......... ('cold',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jringros\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5127\n",
      "           1       0.00      0.00      0.00       109\n",
      "\n",
      "    accuracy                           0.98      5236\n",
      "   macro avg       0.49      0.50      0.49      5236\n",
      "weighted avg       0.96      0.98      0.97      5236\n",
      "\n",
      "Test Score results for Category.......... ('other_weather',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4955\n",
      "           1       0.50      0.00      0.01       281\n",
      "\n",
      "    accuracy                           0.95      5236\n",
      "   macro avg       0.72      0.50      0.49      5236\n",
      "weighted avg       0.92      0.95      0.92      5236\n",
      "\n",
      "Test Score results for Category.......... ('direct_report',)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      4253\n",
      "           1       0.77      0.06      0.12       983\n",
      "\n",
      "    accuracy                           0.82      5236\n",
      "   macro avg       0.79      0.53      0.51      5236\n",
      "weighted avg       0.81      0.82      0.75      5236\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1343532247ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Saving model...\\n    MODEL: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_filepath' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    ''' Performs a series of operations to build a pipeline-based model fitted and tested with information contained in the database file contained in database_filepath,\n",
    "        evaluates the model and stores the model in the path defined by model_filepath\n",
    "    \n",
    "    INPUT:\n",
    "    database_filepath - path of the .db file (database) created and stored by the process_data.py script \n",
    "    model_filepath - path where model will be saved\n",
    "    '''\n",
    "    \n",
    "    #if len(sys.argv) == 3:\n",
    "#database_filepath, model_filepath = sys.argv[1:]\n",
    "#print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "#X, Y, category_names = load_data()#database_filepath)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "#print('Building model...')\n",
    "#model = build_model()\n",
    "\n",
    "#print('Training model...')\n",
    "#model.fit(X_train, Y_train)\n",
    "\n",
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model)\n",
    "\n",
    "print('Trained model saved!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(category_names)\n",
    "for i in category_names:\n",
    "    print(category_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # y_test_pred and y_train_pred are obtaines as numpy arrays\n",
    "    # for further operations, we need to convert them into dataframe\n",
    "    # therefore, y_test_pred_df and y_train_pred_df are introduced:\n",
    "\n",
    "y_headers = y_test.columns\n",
    "\n",
    "\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred, columns = y_headers)\n",
    "print(y_test_pred_df)\n",
    "for col in y_test:\n",
    "    print(y_test_pred_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(category_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('related',)\n",
      "2\n",
      "('request',)\n",
      "3\n",
      "('offer',)\n",
      "4\n",
      "('aid_related',)\n",
      "5\n",
      "('medical_help',)\n",
      "6\n",
      "('medical_products',)\n",
      "7\n",
      "('search_and_rescue',)\n",
      "8\n",
      "('security',)\n",
      "9\n",
      "('military',)\n",
      "10\n",
      "('child_alone',)\n",
      "11\n",
      "('water',)\n",
      "12\n",
      "('food',)\n",
      "13\n",
      "('shelter',)\n",
      "14\n",
      "('clothing',)\n",
      "15\n",
      "('money',)\n",
      "16\n",
      "('missing_people',)\n",
      "17\n",
      "('refugees',)\n",
      "18\n",
      "('death',)\n",
      "19\n",
      "('other_aid',)\n",
      "20\n",
      "('infrastructure_related',)\n",
      "21\n",
      "('transport',)\n",
      "22\n",
      "('buildings',)\n",
      "23\n",
      "('electricity',)\n",
      "24\n",
      "('tools',)\n",
      "25\n",
      "('hospitals',)\n",
      "26\n",
      "('shops',)\n",
      "27\n",
      "('aid_centers',)\n",
      "28\n",
      "('other_infrastructure',)\n",
      "29\n",
      "('weather_related',)\n",
      "30\n",
      "('floods',)\n",
      "31\n",
      "('storm',)\n",
      "32\n",
      "('fire',)\n",
      "33\n",
      "('earthquake',)\n",
      "34\n",
      "('cold',)\n",
      "35\n",
      "('other_weather',)\n",
      "36\n",
      "('direct_report',)\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(category_names)):\n",
    "    print(category_names[i])\n",
    "    p=i+2\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Category ('request',)\n"
     ]
    }
   ],
   "source": [
    "y_headers = Y_test.columns\n",
    "\n",
    "print(\"Results for Category\",y_headers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_test_pred_df = pd.DataFrame(y_test_pred, columns = y_headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
